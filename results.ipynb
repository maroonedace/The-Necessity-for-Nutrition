{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neccessity for Nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cereals = pd.read_csv(\"../data/cereal.csv\")\n",
    "mcd = pd.read_csv(\"../data/menu.csv\")\n",
    "starbucks = pd.read_csv(\"../data/starbucks.csv\", encoding= 'unicode_escape')\n",
    "\n",
    "cereals['mfr'].replace({'K': 1, 'G': 1, 'A': -1, 'N': -1, 'P': -1, 'Q': -1, 'R':-1}, inplace=True)\n",
    "\n",
    "mcd['Category'].replace({'Beef & Pork': -1, 'Chicken & Fish': -1, 'Breakfast': 1}, inplace=True)\n",
    "value_list = [1, -1]\n",
    "mcd = mcd[mcd.Category.isin(value_list)]\n",
    "\n",
    "starbucks['Type'].replace({'Coffee': -1, 'Espresso': 1}, inplace=True)\n",
    "starbucks = starbucks.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organzizing cereal data\n",
    "X = []\n",
    "for i in cereals.itertuples(): \n",
    "    X.append(i[4:12])  \n",
    "    \n",
    "for count,ele in enumerate(X):\n",
    "    X[count] = list(ele)\n",
    "    \n",
    "X = np.array(X)\n",
    "\n",
    "Y = []\n",
    "for i in cereals.mfr:\n",
    "    Y.append([i])\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Organzizing mcd data\n",
    "X1 = []\n",
    "for i in mcd.itertuples(): \n",
    "    X1.append(i[4:17])  \n",
    "    \n",
    "for count,ele in enumerate(X1):\n",
    "    X1[count] = list(ele)\n",
    "    \n",
    "X1 = np.array(X1)\n",
    "\n",
    "Y1 = []\n",
    "for i in mcd.Category:\n",
    "    Y1.append([i])\n",
    "Y1 = np.array(Y1)\n",
    "\n",
    "# Organzizing starbucks data\n",
    "X2 = []\n",
    "for i in starbucks.itertuples(): \n",
    "    X2.append(i[6:15])  \n",
    "    \n",
    "for count,ele in enumerate(X2):\n",
    "    X2[count] = list(ele)\n",
    "    \n",
    "X2 = np.array(X2)\n",
    "\n",
    "Y2 = []\n",
    "for i in starbucks.Type:\n",
    "    Y2.append([i])\n",
    "Y2 = np.array(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_and_Y = np.hstack((X, Y))     # Stack them together for shuffling.            \n",
    "np.random.shuffle(X_and_Y)      # Shuffle the data points in X_and_Y array\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_and_Y[0])\n",
    "\n",
    "X_and_Y1 = np.hstack((X1, Y1))     # Stack them together for shuffling.            \n",
    "np.random.shuffle(X_and_Y1)      # Shuffle the data points in X_and_Y array\n",
    "\n",
    "print(X1.shape)\n",
    "print(Y1.shape)\n",
    "print(X_and_Y1[0]) \n",
    "\n",
    "X_and_Y2 = np.hstack((X2, Y2))     # Stack them together for shuffling.            \n",
    "np.random.shuffle(X_and_Y2)      # Shuffle the data points in X_and_Y array\n",
    "\n",
    "print(X2.shape)\n",
    "print(Y2.shape)\n",
    "print(X_and_Y2[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function: sigmoid(z) = 1/(1 + e^(-z))\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "# Judge function: 1(a != b).\n",
    "def judge(a, b):\n",
    "    if a != b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# Logistic regression classifier.\n",
    "def f_logistic(x, W, b):\n",
    "    # x should be a 2-dimensional vector, \n",
    "    # W should be a 2-dimensional vector,\n",
    "    # b should be a scalar.\n",
    "    # you should return a scalar which is -1 or 1.\n",
    "    zigma = W.dot(x) + b\n",
    "    if sigmoid(zigma) >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# Calculate error given feature vectors X and labels Y.\n",
    "def calc_error1(X, Y, W, b):\n",
    "    errors = 0 \n",
    "    n = len(X)\n",
    "    \n",
    "    for (xi, yi) in zip(X, Y):\n",
    "        errors += judge(yi,f_logistic(xi,W,b))\n",
    "    \n",
    "    return errors/n\n",
    "\n",
    "# Gradient of L(W, b) with respect to W and b.\n",
    "def grad_L_W_b(X, Y, W, b):\n",
    "    one = np.ones(len(X))\n",
    "    P = sigmoid(Y * (X.dot(W) + b * one))\n",
    "\n",
    "    grad_W = -X.T.dot((one-P) * Y)\n",
    "    grad_b = -one.T.dot((one-P) * Y)\n",
    "    return grad_W, grad_b\n",
    "\n",
    "# Loss L(W, b).\n",
    "def L_W_b(X, Y, W, b):\n",
    "    # You should return a scalar.\n",
    "    one = np.ones(len(X))\n",
    "    P = sigmoid(Y * (X.dot(W) + b * one))\n",
    "    \n",
    "    return -one.T.dot(np.log(P))\n",
    "\n",
    "# Judge function: 1(a != b). It supports scalar, vector and matrix.\n",
    "def judge_1(a, b):\n",
    "    return np.array(a != b).astype(np.float32)\n",
    "\n",
    "# Judge function: 1(z > 0). It supports scalar, vector and matrix.\n",
    "def judge_2(z):\n",
    "    return np.array(z > 0).astype(np.float32)\n",
    "    \n",
    "# Rectifier function: (z)_+ = max(0, z). It supports scalar, vector and matrix.\n",
    "def rectifier(z):\n",
    "    return np.clip(z, a_min=0, a_max=None)\n",
    "\n",
    "# Linear SVM classifier.\n",
    "def f_linear_svm(x, W, b):\n",
    "    # x should be a 2-dimensional vector, \n",
    "    # W should be a 2-dimensional vector,\n",
    "    # b should be a scalar.\n",
    "    # you should return a scalar which is -1 or 1. \n",
    "    f_svm = W.T.dot(x) + b\n",
    "    \n",
    "    if f_svm >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# Calculate error given feature vectors X and labels Y.\n",
    "def calc_error2(X, Y, classifier):\n",
    "    Y_pred = classifier.predict(X) # Hint: Use classifier.predict()\n",
    "    e = 1 - accuracy_score(Y_pred, Y) # Hint: Use accuracy_score().\n",
    "    return e\n",
    "\n",
    "# Gradient of L(W, b) with respect to W and b.\n",
    "def grad_L_W_b2(X, Y, W, b, C):\n",
    "    one = np.ones(len(X))\n",
    "    a = one - Y * (X.dot(W) + b * one)\n",
    "    grad_W = W - C * X.T.dot(judge_2(a) * Y)\n",
    "    grad_b = -C * one.T.dot(judge_2(a) * Y)\n",
    "    return grad_W, grad_b\n",
    "\n",
    "# Loss L(W, b).\n",
    "def L_W_b2(X, Y, W, b, C):\n",
    "    one = np.ones(len(X))\n",
    "    a = one - Y * (X.dot(W) + b * one)\n",
    "    return 1/2 * W.T.dot(W) + C * one.T * rectifier(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(X, Y, W=None, b=None):\n",
    "    indices_neg1 = (Y == -1).nonzero()[0]\n",
    "    indices_pos1 = (Y == 1).nonzero()[0]\n",
    "    plt.scatter(X[:,0][indices_neg1], X[:,1][indices_neg1], \n",
    "                c='blue', label='class -1')\n",
    "    plt.scatter(X[:,0][indices_pos1], X[:,1][indices_pos1], \n",
    "                c='red', label='class 1')\n",
    "    plt.legend()\n",
    "    plt.xlabel('$x_0$')\n",
    "    plt.ylabel('$x_1$')\n",
    "    \n",
    "    if W is not None:\n",
    "        # w0x0+w1x1+b=0 => x1=-w0x0/w1-b/w1\n",
    "        w0 = W[0]\n",
    "        w1 = W[1]\n",
    "        temp = -w1*np.array([X[:,1].min(), X[:,1].max()])/w0-b/w0\n",
    "        x0_min = max(temp.min(), X[:,0].min())\n",
    "        x0_max = min(temp.max(), X[:,1].max())\n",
    "        x0 = np.linspace(x0_min,x0_max,100)\n",
    "        x1 = -w0*x0/w1-b/w1\n",
    "        plt.plot(x0,x1,color='black')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def draw_heatmap(errors, D_list, title):\n",
    "    plt.figure(figsize = (2,4))\n",
    "    ax = sns.heatmap(errors, annot=True, fmt='.3f', yticklabels=D_list, xticklabels=[])\n",
    "    ax.collections[0].colorbar.set_label('error')\n",
    "    ax.set(ylabel='max depth D')\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_training_data1 = 0\n",
    "r_testing_data1 = 0\n",
    "\n",
    "def logreg(X_train, Y_train, X_test, Y_test):        \n",
    "    learning_rate = 0.001\n",
    "    iterations  = 10000\n",
    "    losses = []\n",
    "    global r_training_data1\n",
    "    global r_testing_data1\n",
    "\n",
    "    # Gradient descent algorithm for logistic regression.\n",
    "    # Step 1. Initialize the parameters W, b.\n",
    "    W = np.zeros(2) \n",
    "    b = 0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Step 2. Compute the partial derivatives.\n",
    "        grad_W, grad_b = grad_L_W_b(X_train, Y_train, W, b)\n",
    "        # Step 3. Update the parameters.\n",
    "        W = W - learning_rate * grad_W\n",
    "        b = b - learning_rate * grad_b\n",
    "\n",
    "        # Track the training losses.\n",
    "        losses.append(L_W_b(X_train, Y_train, W, b))\n",
    "\n",
    "    # Show decision boundary, training error and test error.\n",
    "    r_training_data1 += calc_error1(X_train, Y_train, W, b)\n",
    "    r_testing_data1 += calc_error1(X_test, Y_test, W, b)\n",
    "    print('Decision boundary: {:.3f}x0+{:.3f}x1+{:.3f}=0'.format(W[0],W[1],b))\n",
    "    vis(X_train, Y_train, W, b)\n",
    "    print('Training error: {}'.format(calc_error1(X_train, Y_train, W, b)))\n",
    "    vis(X_test, Y_test, W, b)\n",
    "    print('Test error: {}'.format(calc_error1(X_test, Y_test, W, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_training_data2 = 0\n",
    "r_testing_data2 = 0\n",
    "\n",
    "def svmf(X_train, Y_train, X_test, Y_test):\n",
    "    # Some settings.\n",
    "    learning_rate = 0.0001\n",
    "    iterations    = 10000\n",
    "    losses = []\n",
    "\n",
    "    global r_training_data2\n",
    "    global r_testing_data2\n",
    "\n",
    "    # Gradient descent algorithm for linear SVM classifier.\n",
    "    # Step 1. Initialize the parameters W, b.\n",
    "    W = np.zeros(2) \n",
    "    b = 0\n",
    "    C = 1000\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Step 2. Compute the partial derivatives.\n",
    "        grad_W, grad_b = grad_L_W_b2(X_train, Y_train, W, b, C) \n",
    "        # Step 3. Update the parameters.\n",
    "        W = W - learning_rate * grad_W\n",
    "        b = b - learning_rate * grad_b\n",
    "\n",
    "        # Track the training losses.\n",
    "        losses.append(L_W_b2(X_train, Y_train, W, b, C))\n",
    "\n",
    "    C_list = [0.1, 1, 10, 100, 1000]\n",
    "    opt_e_training = 1.0   # Optimal training error.\n",
    "    opt_classifier = None  # Optimal classifier.\n",
    "    opt_C          = None  # Optimal C.\n",
    "\n",
    "    for C in C_list:\n",
    "        # Create a linear SVM classifier.\n",
    "        # Hints: You can use svm.LinearSVC()\n",
    "        #        Besides, we use Hinge loss and L2 penalty for weights.\n",
    "        #        The max iterations should be set to 10000.\n",
    "        #        The regularization parameter should be set as C.\n",
    "        #        The other arguments of svm.LinearSVC() are set as default values.\n",
    "        classifier = svm.LinearSVC(penalty = 'l2', loss = 'hinge', max_iter = 10000, C = C)\n",
    "    \n",
    "        # Use the classifier to fit the training set (use X_train, Y_train).\n",
    "        # Hint: You can use classifier.fit().\n",
    "        classifier.fit(X_train, Y_train)\n",
    "\n",
    "        # Obtain the weights and bias from the linear SVM classifier.\n",
    "        W = classifier.coef_[0]\n",
    "        b = classifier.intercept_[0]\n",
    "    \n",
    "        # Show decision boundary, training error and test error.\n",
    "        print(\"Test #1\")\n",
    "        print('C = {}'.format(C))\n",
    "        print('Decision boundary: {:.3f}x0+{:.3f}x1+{:.3f}=0'.format(W[0],W[1],b))\n",
    "        vis(X_train, Y_train, W, b)\n",
    "        e_training = calc_error2(X_train, Y_train, classifier)\n",
    "        print('Training error: {}'.format(e_training))\n",
    "        print('\\n\\n\\n')\n",
    "    \n",
    "        # Judge if it is the optimal one.\n",
    "        if e_training < opt_e_training:\n",
    "            opt_e_training = e_training\n",
    "            opt_classifier = classifier\n",
    "            opt_C = C\n",
    "\n",
    "    r_training_data2 += opt_e_training\n",
    "    \n",
    "    # Obtain the weights and bias from the best linear SVM classifier .\n",
    "    opt_W = opt_classifier.coef_[0]\n",
    "    opt_b = opt_classifier.intercept_[0]\n",
    "    print('Best parameter C* = {}'.format(opt_C))\n",
    "    print('Decision boundary: {:.3f}x0+{:.3f}x1+{:.3f}=0'.format(opt_W[0],opt_W[1],opt_b))\n",
    "    vis(X_test, Y_test, opt_W, opt_b)\n",
    "    print('Test error: {}'.format(calc_error2(X_test, Y_test, opt_classifier)))\n",
    "\n",
    "    r_testing_data2 += calc_error2(X_test, Y_test, opt_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_training_data3 = 0\n",
    "r_testing_data3 = 0\n",
    "\n",
    "def trees(X_train,Y_train,X_test,Y_test):\n",
    "    # Perform grid search for best max depth.\n",
    "    global r_training_data3 \n",
    "    global r_testing_data3 \n",
    "\n",
    "    # 1. Create a decision tree classifier.\n",
    "    estimator = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 1)\n",
    "    # 2. Create a grid searcher with cross-validation.\n",
    "    D_list = [1, 2, 3, 4, 5]\n",
    "    param_grid = {'max_depth': D_list}\n",
    "    grid_search = GridSearchCV(estimator = estimator, param_grid = param_grid, cv = 5)\n",
    "    # 3. Use the grid searcher to fit the training set.\n",
    "    #    Hint: You can simply use .fit() function of the grid searcher.\n",
    "    grid_search.fit(X_train,Y_train)\n",
    "    \n",
    "    # Draw heatmaps of cross-validation errors (in cross-validation).\n",
    "    cross_val_errors = 1 - grid_search.cv_results_['mean_test_score'].reshape(-1,1)\n",
    "    draw_heatmap(cross_val_errors, D_list, title='cross-validation error w.r.t D')\n",
    "    \n",
    "    # Show the best max depth.\n",
    "    best_max_depth = grid_search.best_params_\n",
    "    print(\"Best max depth D: {}\".format(best_max_depth))\n",
    "    \n",
    "    # Calculate the training error.\n",
    "    # Hint: You can use .best_estimator_.predict() to make predictions.\n",
    "    X_train = grid_search.best_estimator_.predict(X_train)\n",
    "    train_error = 1 - accuracy_score(X_train, Y_train)\n",
    "    print(\"Training error: {}\".format(train_error))\n",
    "    \n",
    "    # Calculate the test error.\n",
    "    # Hint: You can use .best_estimator_.predict() to make predictions.\n",
    "    X_test = grid_search.best_estimator_.predict(X_test)\n",
    "    test_error = 1 - accuracy_score(X_test, Y_test)\n",
    "    print(\"Test error: {}\".format(test_error))\n",
    "\n",
    "    r_training_data3 += train_error\n",
    "    r_testing_data3 += test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "    \n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]]\n",
    "Y_train = Y_shuffled[:15]\n",
    "X_test  = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test  = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]]\n",
    "Y_train = Y_shuffled[:15]\n",
    "X_test  = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test  = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]]\n",
    "Y_train = Y_shuffled[:15]\n",
    "X_test  = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test  = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data111 = r_training_data1/3\n",
    "totalr_testing_data111 = r_testing_data1/3\n",
    "r_training_data1 = 0\n",
    "r_testing_data1 = 0\n",
    "print(\"Training average :\",totalr_training_data111)\n",
    "print(\"Training average :\",totalr_testing_data111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:15] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:15] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:15] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data112 = r_training_data2/3\n",
    "totalr_testing_data112 = r_testing_data2/3\n",
    "r_training_data2 = 0\n",
    "r_testing_data2 = 0\n",
    "print(\"Training average :\",totalr_training_data112)\n",
    "print(\"Training average :\",totalr_testing_data112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:15] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:15] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "\n",
    "X_train = X_shuffled[:15][:,[6,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:15] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[15:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[15:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data113 = r_training_data3/3\n",
    "totalr_testing_data113 = r_testing_data3/3\n",
    "r_training_data3 = 0\n",
    "r_testing_data3 = 0\n",
    "print(\"Training average :\",totalr_training_data113)\n",
    "print(\"Training average :\",totalr_testing_data113)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]]\n",
    "Y_train = Y_shuffled[:62]\n",
    "X_test  = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test  = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]]\n",
    "Y_train = Y_shuffled[:62]\n",
    "X_test  = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test  = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]]\n",
    "Y_train = Y_shuffled[:62]\n",
    "X_test  = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test  = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data121 = r_training_data1/3\n",
    "totalr_testing_data121 = r_testing_data1/3\n",
    "r_training_data1 = 0\n",
    "r_testing_data1 = 0\n",
    "print(\"Training average :\",totalr_training_data121)\n",
    "print(\"Training average :\",totalr_testing_data121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:62] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:62] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:62] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data122 = r_training_data2/3\n",
    "totalr_testing_data122 = r_testing_data2/3\n",
    "r_training_data2 = 0\n",
    "r_testing_data2 = 0\n",
    "print(\"Training average :\",totalr_training_data122)\n",
    "print(\"Training average :\",totalr_testing_data122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:62] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:62] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y) \n",
    "X_shuffled = X_and_Y[:,:8]\n",
    "Y_shuffled = X_and_Y[:,8]\n",
    "\n",
    "X_train = X_shuffled[:62][:,[6,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:62] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[62:78][:,[6,0]]\n",
    "Y_test = Y_shuffled[62:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data123 = r_training_data3/3\n",
    "totalr_testing_data123 = r_testing_data3/3\n",
    "r_training_data3 = 0\n",
    "r_testing_data3 = 0\n",
    "print(\"Training average :\",totalr_training_data123)\n",
    "print(\"Training average :\",totalr_testing_data123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training average Log Regression :\",totalr_training_data111)\n",
    "print(\"Training average SVM :\",totalr_training_data112)\n",
    "print(\"Training average Decision Tree :\",totalr_training_data113)\n",
    "\n",
    "print(\"Testing average Log Regression :\",totalr_testing_data111)\n",
    "print(\"Testing average SVM :\",totalr_testing_data112)\n",
    "print(\"Testing average Decision Tree :\",totalr_testing_data113)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Training average Log Regression :\",totalr_training_data121)\n",
    "print(\"Training average SVM :\",totalr_training_data122)\n",
    "print(\"Training average Decision Tree :\",totalr_training_data123)\n",
    "\n",
    "print(\"Testing average Log Regression :\",totalr_testing_data121)\n",
    "print(\"Testing average SVM :\",totalr_testing_data122)\n",
    "print(\"Testing average Decision Tree :\",totalr_testing_data123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "    \n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]]\n",
    "Y_train = Y_shuffled[:17]\n",
    "X_test  = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test  = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "    \n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]]\n",
    "Y_train = Y_shuffled[:17]\n",
    "X_test  = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test  = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "    \n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]]\n",
    "Y_train = Y_shuffled[:17]\n",
    "X_test  = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test  = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data211 = r_training_data1/3\n",
    "totalr_testing_data211 = r_testing_data1/3\n",
    "r_training_data1 = 0\n",
    "r_testing_data1 = 0\n",
    "print(\"Training average :\",totalr_training_data211)\n",
    "print(\"Training average :\",totalr_testing_data211)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:17] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:17] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:17] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data212 = r_training_data2/3\n",
    "totalr_testing_data212 = r_testing_data2/3\n",
    "r_training_data2 = 0\n",
    "r_testing_data2 = 0\n",
    "print(\"Training average :\",totalr_training_data212)\n",
    "print(\"Training average :\",totalr_testing_data212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:17] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:17] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:17][:,[2,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:17] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[17:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[17:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data213 = r_training_data3/3\n",
    "totalr_testing_data213 = r_testing_data3/3\n",
    "r_training_data3 = 0\n",
    "r_testing_data3 = 0\n",
    "print(\"Training average :\",totalr_training_data213)\n",
    "print(\"Training average :\",totalr_testing_data213)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "    \n",
    "X_train = X_shuffled[:67][:,[2,0]]\n",
    "Y_train = Y_shuffled[:67]\n",
    "X_test  = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test  = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "    \n",
    "X_train = X_shuffled[:67][:,[2,0]]\n",
    "Y_train = Y_shuffled[:67]\n",
    "X_test  = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test  = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "    \n",
    "X_train = X_shuffled[:67][:,[2,0]]\n",
    "Y_train = Y_shuffled[:67]\n",
    "X_test  = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test  = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data221 = r_training_data1/3\n",
    "totalr_testing_data221 = r_testing_data1/3\n",
    "r_training_data1 = 0\n",
    "r_testing_data1 = 0\n",
    "print(\"Training average :\",totalr_training_data221)\n",
    "print(\"Training average :\",totalr_testing_data221)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:67][:,[2,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:67] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:67][:,[2,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:67] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:67][:,[2,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:67] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data222 = r_training_data2/3\n",
    "totalr_testing_data222 = r_testing_data2/3\n",
    "r_training_data2 = 0\n",
    "r_testing_data2 = 0\n",
    "print(\"Training average :\",totalr_training_data222)\n",
    "print(\"Training average :\",totalr_testing_data222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:67][:,[2,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:67] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:67][:,[2,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:67] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y1) \n",
    "X_shuffled = X_and_Y1[:,:8]\n",
    "Y_shuffled = X_and_Y1[:,13]\n",
    "\n",
    "X_train = X_shuffled[:67][:,[2,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:67] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[67:85][:,[2,0]]\n",
    "Y_test = Y_shuffled[67:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data223 = r_training_data3/3\n",
    "totalr_testing_data223 = r_testing_data3/3\n",
    "r_training_data3 = 0\n",
    "r_testing_data3 = 0\n",
    "print(\"Training average :\",totalr_training_data223)\n",
    "print(\"Training average :\",totalr_testing_data223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training average Log Regression :\",totalr_training_data211)\n",
    "print(\"Training average SVM :\",totalr_training_data212)\n",
    "print(\"Training average Decision Tree :\",totalr_training_data213)\n",
    "\n",
    "print(\"Testing average Log Regression :\",totalr_testing_data211)\n",
    "print(\"Testing average SVM :\",totalr_testing_data212)\n",
    "print(\"Testing average Decision Tree :\",totalr_testing_data213)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Training average Log Regression :\",totalr_training_data221)\n",
    "print(\"Training average SVM :\",totalr_training_data222)\n",
    "print(\"Training average Decision Tree :\",totalr_training_data223)\n",
    "\n",
    "print(\"Testing average Log Regression :\",totalr_testing_data221)\n",
    "print(\"Testing average SVM :\",totalr_testing_data222)\n",
    "print(\"Testing average Decision Tree :\",totalr_testing_data223)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "    \n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]]\n",
    "Y_train = Y_shuffled[:92]\n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "    \n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]]\n",
    "Y_train = Y_shuffled[:92]\n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "    \n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]]\n",
    "Y_train = Y_shuffled[:92]\n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data311 = r_training_data1/3\n",
    "totalr_testing_data311 = r_testing_data1/3\n",
    "r_training_data1 = 0\n",
    "r_testing_data1 = 0\n",
    "print(\"Training average :\",totalr_training_data311)\n",
    "print(\"Training average :\",totalr_testing_data311)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:92] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:92] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:92] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data312 = r_training_data2/3\n",
    "totalr_testing_data312 = r_testing_data2/3\n",
    "r_training_data2 = 0\n",
    "r_testing_data2 = 0\n",
    "print(\"Training average :\",totalr_training_data312)\n",
    "print(\"Training average :\",totalr_testing_data312)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:92] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:92] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:92][:,[7,0]] \n",
    "X_train = np.delete(X_train, 11, axis=0) \n",
    "Y_train = Y_shuffled[:92] \n",
    "Y_train = np.delete(Y_train, 11, axis=0) \n",
    "X_test = X_shuffled[92:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[92:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data313 = r_training_data3/3\n",
    "totalr_testing_data313 = r_testing_data3/3\n",
    "r_training_data3 = 0\n",
    "r_testing_data3 = 0\n",
    "print(\"Training average :\",totalr_training_data313)\n",
    "print(\"Training average :\",totalr_testing_data313)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]]\n",
    "Y_train = Y_shuffled[:370]\n",
    "X_test  = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test  = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]]\n",
    "Y_train = Y_shuffled[:370]\n",
    "X_test  = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test  = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]]\n",
    "Y_train = Y_shuffled[:370]\n",
    "X_test  = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test  = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data321 = r_training_data1/3\n",
    "totalr_testing_data321 = r_testing_data1/3\n",
    "r_training_data1 = 0\n",
    "r_testing_data1 = 0\n",
    "print(\"Training average :\",totalr_training_data321)\n",
    "print(\"Training average :\",totalr_testing_data321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:370] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:370] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:370] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmf(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data322 = r_training_data2/3\n",
    "totalr_testing_data322 = r_testing_data2/3\n",
    "r_training_data2 = 0\n",
    "r_testing_data2 = 0\n",
    "print(\"Training average :\",totalr_training_data322)\n",
    "print(\"Training average :\",totalr_testing_data322)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:370] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:370] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_and_Y2) \n",
    "X_shuffled = X_and_Y2[:,:9]\n",
    "Y_shuffled = X_and_Y2[:,9]\n",
    "\n",
    "X_train = X_shuffled[:370][:,[7,0]] \n",
    "X_train = np.delete(X_train, 42, axis=0) \n",
    "Y_train = Y_shuffled[:370] \n",
    "Y_train = np.delete(Y_train, 42, axis=0) \n",
    "X_test = X_shuffled[370:463][:,[7,0]]\n",
    "Y_test = Y_shuffled[370:463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees(X_train,Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalr_training_data323 = r_training_data3/3\n",
    "totalr_testing_data323 = r_testing_data3/3\n",
    "r_training_data3 = 0\n",
    "r_testing_data3 = 0\n",
    "print(\"Training average :\",totalr_training_data323)\n",
    "print(\"Training average :\",totalr_testing_data323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training average Log Regression :\",totalr_training_data311)\n",
    "print(\"Training average SVM :\",totalr_training_data312)\n",
    "print(\"Training average Decision Tree :\",totalr_training_data313)\n",
    "\n",
    "print(\"Testing average Log Regression :\",totalr_testing_data311)\n",
    "print(\"Testing average SVM :\",totalr_testing_data312)\n",
    "print(\"Testing average Decision Tree :\",totalr_testing_data313)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Training average Log Regression :\",totalr_training_data321)\n",
    "print(\"Training average SVM :\",totalr_training_data322)\n",
    "print(\"Training average Decision Tree :\",totalr_training_data323)\n",
    "\n",
    "print(\"Testing average Log Regression :\",totalr_testing_data321)\n",
    "print(\"Testing average SVM :\",totalr_testing_data322)\n",
    "print(\"Testing average Decision Tree :\",totalr_testing_data323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_average11 = (totalr_testing_data111 + totalr_testing_data211 + totalr_testing_data311)/3\n",
    "testing_average12 = (totalr_testing_data112 + totalr_testing_data212 + totalr_testing_data312)/3\n",
    "testing_average13 = (totalr_testing_data113 + totalr_testing_data213 + totalr_testing_data313)/3\n",
    "\n",
    "testing_average21 = (totalr_testing_data121 + totalr_testing_data221 + totalr_testing_data321)/3\n",
    "testing_average22 = (totalr_testing_data122 + totalr_testing_data222 + totalr_testing_data322)/3\n",
    "testing_average23 = (totalr_testing_data123 + totalr_testing_data223 + totalr_testing_data323)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {'Classifier': ['Logical Regression', 'SVM', 'Decision Tree'],\n",
    "        'A (20/80) Training Accuracy': [totalr_training_data111, totalr_training_data112, totalr_training_data113],\n",
    "        'A (20/80) Testing Accuracy': [totalr_testing_data111, totalr_testing_data112, totalr_testing_data113],\n",
    "        'B (20/80) Training Accuracy': [totalr_training_data211, totalr_training_data212, totalr_training_data213],\n",
    "        'B (20/80) Testing Accuracy': [totalr_testing_data211, totalr_testing_data212, totalr_testing_data213],\n",
    "        'C (20/80) Training Accuracy': [totalr_training_data311, totalr_training_data312, totalr_training_data313],\n",
    "        'C (20/80) Testing Accuracy': [totalr_testing_data311, totalr_testing_data312, totalr_testing_data313],\n",
    "        'Average Testing Accuracy': [testing_average11, testing_average12, testing_average13]}\n",
    "\n",
    "data2 = {'Classifier': ['Logical Regression', 'SVM', 'Decision Tree'],\n",
    "        'A (80/20) Training Accuracy': [totalr_training_data121, totalr_training_data122, totalr_training_data123],\n",
    "        'A (80/20) Testing Accuracy': [totalr_testing_data121, totalr_testing_data122, totalr_testing_data123],\n",
    "        'B (80/20) Training Accuracy': [totalr_training_data221, totalr_training_data222, totalr_training_data223],\n",
    "        'B (80/20) Testing Accuracy': [totalr_testing_data221, totalr_testing_data222, totalr_testing_data223],\n",
    "        'C (80/20) Training Accuracy': [totalr_training_data321, totalr_training_data322, totalr_training_data323],\n",
    "        'C (80/20) Testing Accuracy': [totalr_testing_data321, totalr_testing_data322, totalr_testing_data323],\n",
    "        'Average Testing Accuracy': [testing_average21, testing_average22, testing_average23]}\n",
    "\n",
    "df = pd.DataFrame (data1, columns = ['Classifier','A (20/80) Training Accuracy', 'A (20/80) Testing Accuracy', 'B (20/80) Training Accuracy',\n",
    "                                    'B (20/80) Testing Accuracy', 'C (20/80) Training Accuracy', 'C (20/80) Testing Accuracy',\n",
    "                                    'Average Testing Accuracy'])\n",
    "df2 = pd.DataFrame (data2, columns = ['Classifier','A (80/20) Training Accuracy', 'A (80/20) Testing Accuracy', 'B (80/20) Training Accuracy',\n",
    "                                    'B (80/20) Testing Accuracy', 'C (80/20) Training Accuracy', 'C (80/20) Testing Accuracy',\n",
    "                                    'Average Testing Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
